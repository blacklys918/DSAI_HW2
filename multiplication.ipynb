{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6>Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yang\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "from six.moves import range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6> Parameters Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class colors:\n",
    "    ok = '\\033[92m'\n",
    "    fail = '\\033[91m'\n",
    "    close = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_SIZE = 80000\n",
    "DIGITS = 3\n",
    "REVERSE = False\n",
    "MAXLEN = DIGITS + 1 + DIGITS\n",
    "chars = '0123456789x '\n",
    "RNN = layers.LSTM\n",
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 128\n",
    "LAYERS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacterTable(object):\n",
    "    def __init__(self, chars):\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "    \n",
    "    def encode(self, C, num_rows):\n",
    "        x = np.zeros((num_rows, len(self.chars)))\n",
    "        for i, c in enumerate(C):\n",
    "            x[i, self.char_indices[c]] = 1\n",
    "        return x\n",
    "    \n",
    "    def decode(self, x, calc_argmax=True):\n",
    "        if calc_argmax:\n",
    "            x = x.argmax(axis=-1)\n",
    "        return \"\".join(self.indices_char[i] for i in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctable = CharacterTable(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ' ',\n",
       " 1: '0',\n",
       " 2: '1',\n",
       " 3: '2',\n",
       " 4: '3',\n",
       " 5: '4',\n",
       " 6: '5',\n",
       " 7: '6',\n",
       " 8: '7',\n",
       " 9: '8',\n",
       " 10: '9',\n",
       " 11: 'x'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctable.indices_char"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6> Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "Total addition questions: 80000\n"
     ]
    }
   ],
   "source": [
    "questions = []\n",
    "expected = []\n",
    "seen = set()\n",
    "print('Generating data...')\n",
    "while len(questions) < TRAINING_SIZE:\n",
    "    f = lambda: int(''.join(np.random.choice(list('0123456789')) for i in range(np.random.randint(1, DIGITS + 1))))\n",
    "    a, b = f(), f()\n",
    "    key = tuple(sorted((a, b)))\n",
    "    if key in seen:\n",
    "        continue\n",
    "    seen.add(key)\n",
    "    q = '{}x{}'.format(a, b)\n",
    "    query = q + ' ' * (MAXLEN - len(q))\n",
    "    ans = str(a * b)\n",
    "    ans += ' ' * (DIGITS + 3 - len(ans))\n",
    "    if REVERSE:\n",
    "        query = query[::-1]\n",
    "    questions.append(query)\n",
    "    expected.append(ans)\n",
    "print('Total addition questions:', len(questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0x980  ', '72x39  ', '29x942 ', '397x30 ', '4x8    '] ['0     ', '2808  ', '27318 ', '11910 ', '32    ']\n"
     ]
    }
   ],
   "source": [
    "print(questions[:5], expected[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6>Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(expected), DIGITS + 3, len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(questions):\n",
    "    x[i] = ctable.encode(sentence, MAXLEN)\n",
    "for i, sentence in enumerate(expected):\n",
    "    y[i] = ctable.encode(sentence, DIGITS + 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "(36000, 7, 12)\n",
      "(36000, 6, 12)\n",
      "Validation Data:\n",
      "(4000, 7, 12)\n",
      "(4000, 6, 12)\n",
      "Testing Data:\n",
      "(40000, 7, 12)\n",
      "(40000, 6, 12)\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(len(y))\n",
    "np.random.shuffle(indices)\n",
    "x = x[indices]\n",
    "y = y[indices]\n",
    "\n",
    "# train_test_split\n",
    "train_x = x[:40000]\n",
    "train_y = y[:40000]\n",
    "test_x = x[40000:]\n",
    "test_y = y[40000:]\n",
    "\n",
    "split_at = len(train_x) - len(train_x) // 10\n",
    "(x_train, x_val) = train_x[:split_at], train_x[split_at:]\n",
    "(y_train, y_val) = train_y[:split_at], train_y[split_at:]\n",
    "\n",
    "print('Training Data:')\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print('Validation Data:')\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)\n",
    "\n",
    "print('Testing Data:')\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  [[[False False False False False  True False False False False False\n",
      "   False]\n",
      "  [False False False False False False False False False False  True\n",
      "   False]\n",
      "  [False False False False False False False  True False False False\n",
      "   False]\n",
      "  [False False False False False False False False False False False\n",
      "    True]\n",
      "  [False False  True False False False False False False False False\n",
      "   False]\n",
      "  [False False  True False False False False False False False False\n",
      "   False]\n",
      "  [ True False False False False False False False False False False\n",
      "   False]]\n",
      "\n",
      " [[False False False False False False False False  True False False\n",
      "   False]\n",
      "  [False False False False False False False False False False False\n",
      "    True]\n",
      "  [False False  True False False False False False False False False\n",
      "   False]\n",
      "  [False False False False False False  True False False False False\n",
      "   False]\n",
      "  [False False  True False False False False False False False False\n",
      "   False]\n",
      "  [ True False False False False False False False False False False\n",
      "   False]\n",
      "  [ True False False False False False False False False False False\n",
      "   False]]\n",
      "\n",
      " [[False False  True False False False False False False False False\n",
      "   False]\n",
      "  [False False  True False False False False False False False False\n",
      "   False]\n",
      "  [False  True False False False False False False False False False\n",
      "   False]\n",
      "  [False False False False False False False False False False False\n",
      "    True]\n",
      "  [False False  True False False False False False False False False\n",
      "   False]\n",
      "  [False False False False False False False False False False  True\n",
      "   False]\n",
      "  [False False False False False  True False False False False False\n",
      "   False]]] \n",
      "\n",
      " label:  [[[False False False False False False  True False False False False\n",
      "   False]\n",
      "  [False False False False False  True False False False False False\n",
      "   False]\n",
      "  [False False False False False False  True False False False False\n",
      "   False]\n",
      "  [False False False False False False False  True False False False\n",
      "   False]\n",
      "  [ True False False False False False False False False False False\n",
      "   False]\n",
      "  [ True False False False False False False False False False False\n",
      "   False]]\n",
      "\n",
      " [[False False  True False False False False False False False False\n",
      "   False]\n",
      "  [False  True False False False False False False False False False\n",
      "   False]\n",
      "  [False False False False False False  True False False False False\n",
      "   False]\n",
      "  [False False False False False False False False  True False False\n",
      "   False]\n",
      "  [ True False False False False False False False False False False\n",
      "   False]\n",
      "  [ True False False False False False False False False False False\n",
      "   False]]\n",
      "\n",
      " [[False False False  True False False False False False False False\n",
      "   False]\n",
      "  [False False  True False False False False False False False False\n",
      "   False]\n",
      "  [False False False False  True False False False False False False\n",
      "   False]\n",
      "  [False False False False False  True False False False False False\n",
      "   False]\n",
      "  [False  True False False False False False False False False False\n",
      "   False]\n",
      "  [ True False False False False False False False False False False\n",
      "   False]]]\n"
     ]
    }
   ],
   "source": [
    "print(\"input: \", x_train[:3], '\\n\\n', \"label: \", y_train[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6> Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128)               72192     \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 6, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 6, 128)            131584    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 6, 12)             1548      \n",
      "=================================================================\n",
      "Total params: 205,324\n",
      "Trainable params: 205,324\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\"Build model...\")\n",
    "model = Sequential()\n",
    "model.add(RNN(HIDDEN_SIZE, input_shape=(MAXLEN, len(chars))))\n",
    "model.add(layers.RepeatVector(DIGITS + 3))\n",
    "\n",
    "for _ in range(LAYERS):\n",
    "    model.add(RNN(HIDDEN_SIZE, return_sequences= True))\n",
    "\n",
    "model.add(layers.TimeDistributed(layers.Dense(len(chars), activation= \"softmax\")))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6>Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 0\n",
      "Train on 36000 samples, validate on 4000 samples\n",
      "Epoch 1/100\n",
      "36000/36000 [==============================] - 9s 254us/step - loss: 1.9368 - acc: 0.2898 - val_loss: 1.8327 - val_acc: 0.3142\n",
      "Epoch 2/100\n",
      "36000/36000 [==============================] - 8s 214us/step - loss: 1.8107 - acc: 0.3174 - val_loss: 1.7888 - val_acc: 0.3176\n",
      "Epoch 3/100\n",
      "36000/36000 [==============================] - 8s 215us/step - loss: 1.7448 - acc: 0.3335 - val_loss: 1.7129 - val_acc: 0.3388\n",
      "Epoch 4/100\n",
      "36000/36000 [==============================] - 8s 214us/step - loss: 1.6485 - acc: 0.3644 - val_loss: 1.6009 - val_acc: 0.3785\n",
      "Epoch 5/100\n",
      "36000/36000 [==============================] - 8s 214us/step - loss: 1.5402 - acc: 0.3999 - val_loss: 1.4857 - val_acc: 0.4157\n",
      "Epoch 6/100\n",
      "36000/36000 [==============================] - 8s 214us/step - loss: 1.4503 - acc: 0.4264 - val_loss: 1.4224 - val_acc: 0.4322\n",
      "Epoch 7/100\n",
      "36000/36000 [==============================] - 8s 213us/step - loss: 1.3861 - acc: 0.4474 - val_loss: 1.3773 - val_acc: 0.4479\n",
      "Epoch 8/100\n",
      "36000/36000 [==============================] - 8s 214us/step - loss: 1.3488 - acc: 0.4617 - val_loss: 1.3533 - val_acc: 0.4510\n",
      "Epoch 9/100\n",
      "36000/36000 [==============================] - 8s 215us/step - loss: 1.3108 - acc: 0.4779 - val_loss: 1.3278 - val_acc: 0.4697\n",
      "Epoch 10/100\n",
      "36000/36000 [==============================] - 8s 213us/step - loss: 1.2832 - acc: 0.4873 - val_loss: 1.2696 - val_acc: 0.4901\n",
      "Epoch 11/100\n",
      "36000/36000 [==============================] - 8s 214us/step - loss: 1.2552 - acc: 0.4996 - val_loss: 1.2459 - val_acc: 0.5063\n",
      "Epoch 12/100\n",
      "36000/36000 [==============================] - 8s 214us/step - loss: 1.2341 - acc: 0.5073 - val_loss: 1.2388 - val_acc: 0.5099\n",
      "Epoch 13/100\n",
      "36000/36000 [==============================] - 8s 213us/step - loss: 1.2156 - acc: 0.5149 - val_loss: 1.2067 - val_acc: 0.5177\n",
      "Epoch 14/100\n",
      "36000/36000 [==============================] - 8s 214us/step - loss: 1.1920 - acc: 0.5247 - val_loss: 1.1902 - val_acc: 0.5243\n",
      "Epoch 15/100\n",
      "36000/36000 [==============================] - 8s 214us/step - loss: 1.1762 - acc: 0.5314 - val_loss: 1.1875 - val_acc: 0.5215\n",
      "Epoch 16/100\n",
      "36000/36000 [==============================] - 8s 212us/step - loss: 1.1590 - acc: 0.5362 - val_loss: 1.1862 - val_acc: 0.5188\n",
      "Epoch 17/100\n",
      "36000/36000 [==============================] - 8s 213us/step - loss: 1.1482 - acc: 0.5397 - val_loss: 1.1482 - val_acc: 0.5307\n",
      "Epoch 18/100\n",
      "36000/36000 [==============================] - 8s 216us/step - loss: 1.1292 - acc: 0.5479 - val_loss: 1.1378 - val_acc: 0.5392\n",
      "Epoch 19/100\n",
      "36000/36000 [==============================] - 8s 216us/step - loss: 1.1148 - acc: 0.5532 - val_loss: 1.1264 - val_acc: 0.5435\n",
      "Epoch 20/100\n",
      "36000/36000 [==============================] - 8s 213us/step - loss: 1.0988 - acc: 0.5606 - val_loss: 1.1103 - val_acc: 0.5503\n",
      "Epoch 21/100\n",
      "36000/36000 [==============================] - 8s 214us/step - loss: 1.0856 - acc: 0.5641 - val_loss: 1.1106 - val_acc: 0.5433\n",
      "Epoch 22/100\n",
      "36000/36000 [==============================] - 8s 218us/step - loss: 1.0781 - acc: 0.5665 - val_loss: 1.0747 - val_acc: 0.5686\n",
      "Epoch 23/100\n",
      "36000/36000 [==============================] - 8s 215us/step - loss: 1.0667 - acc: 0.5701 - val_loss: 1.1083 - val_acc: 0.5389\n",
      "Epoch 24/100\n",
      "36000/36000 [==============================] - 8s 214us/step - loss: 1.0588 - acc: 0.5740 - val_loss: 1.0707 - val_acc: 0.5615\n",
      "Epoch 25/100\n",
      "36000/36000 [==============================] - 8s 215us/step - loss: 1.0475 - acc: 0.5797 - val_loss: 1.1036 - val_acc: 0.5505\n",
      "Epoch 26/100\n",
      "36000/36000 [==============================] - 8s 214us/step - loss: 1.0384 - acc: 0.5870 - val_loss: 1.0292 - val_acc: 0.5928\n",
      "Epoch 27/100\n",
      "36000/36000 [==============================] - 8s 216us/step - loss: 1.0136 - acc: 0.6025 - val_loss: 1.0153 - val_acc: 0.6010\n",
      "Epoch 28/100\n",
      "36000/36000 [==============================] - 8s 215us/step - loss: 0.9880 - acc: 0.6170 - val_loss: 0.9832 - val_acc: 0.6191\n",
      "Epoch 29/100\n",
      "36000/36000 [==============================] - 8s 215us/step - loss: 0.9524 - acc: 0.6363 - val_loss: 0.9553 - val_acc: 0.6394\n",
      "Epoch 30/100\n",
      "36000/36000 [==============================] - 8s 217us/step - loss: 0.9176 - acc: 0.6505 - val_loss: 0.9533 - val_acc: 0.6248\n",
      "Epoch 31/100\n",
      "36000/36000 [==============================] - 8s 215us/step - loss: 0.8899 - acc: 0.6624 - val_loss: 0.8899 - val_acc: 0.6591\n",
      "Epoch 32/100\n",
      "36000/36000 [==============================] - 8s 216us/step - loss: 0.8686 - acc: 0.6691 - val_loss: 0.8854 - val_acc: 0.6584\n",
      "Epoch 33/100\n",
      "36000/36000 [==============================] - 8s 217us/step - loss: 0.8572 - acc: 0.6719 - val_loss: 0.8662 - val_acc: 0.6645\n",
      "Epoch 34/100\n",
      "36000/36000 [==============================] - 8s 216us/step - loss: 0.8547 - acc: 0.6701 - val_loss: 0.8520 - val_acc: 0.6682\n",
      "Epoch 35/100\n",
      "36000/36000 [==============================] - 8s 215us/step - loss: 0.8276 - acc: 0.6835 - val_loss: 0.8416 - val_acc: 0.6739\n",
      "Epoch 36/100\n",
      "36000/36000 [==============================] - 8s 215us/step - loss: 0.8258 - acc: 0.6817 - val_loss: 0.8291 - val_acc: 0.6809\n",
      "Epoch 37/100\n",
      "36000/36000 [==============================] - 8s 216us/step - loss: 0.8134 - acc: 0.6859 - val_loss: 0.8735 - val_acc: 0.6484\n",
      "Epoch 38/100\n",
      "36000/36000 [==============================] - 8s 217us/step - loss: 0.8106 - acc: 0.6867 - val_loss: 0.8400 - val_acc: 0.6740\n",
      "Epoch 39/100\n",
      "36000/36000 [==============================] - 8s 215us/step - loss: 0.7945 - acc: 0.6945 - val_loss: 0.8691 - val_acc: 0.6485\n",
      "Epoch 40/100\n",
      "36000/36000 [==============================] - 8s 216us/step - loss: 0.7932 - acc: 0.6928 - val_loss: 0.8300 - val_acc: 0.6704\n",
      "Epoch 41/100\n",
      "36000/36000 [==============================] - 8s 218us/step - loss: 0.7824 - acc: 0.6966 - val_loss: 0.7963 - val_acc: 0.6883\n",
      "Epoch 42/100\n",
      "36000/36000 [==============================] - 8s 217us/step - loss: 0.7842 - acc: 0.6945 - val_loss: 0.8007 - val_acc: 0.6869\n",
      "Epoch 43/100\n",
      "36000/36000 [==============================] - 8s 215us/step - loss: 0.7697 - acc: 0.7011 - val_loss: 0.8391 - val_acc: 0.6665\n",
      "Epoch 44/100\n",
      "36000/36000 [==============================] - 8s 215us/step - loss: 0.7700 - acc: 0.7005 - val_loss: 0.7862 - val_acc: 0.6923\n",
      "Epoch 45/100\n",
      "36000/36000 [==============================] - 8s 216us/step - loss: 0.7661 - acc: 0.7018 - val_loss: 0.7824 - val_acc: 0.6890\n",
      "Epoch 46/100\n",
      "36000/36000 [==============================] - 8s 215us/step - loss: 0.7567 - acc: 0.7059 - val_loss: 0.8231 - val_acc: 0.6710\n",
      "Epoch 47/100\n",
      "36000/36000 [==============================] - 8s 215us/step - loss: 0.7581 - acc: 0.7032 - val_loss: 0.7871 - val_acc: 0.6873\n",
      "Epoch 48/100\n",
      "36000/36000 [==============================] - 8s 215us/step - loss: 0.7428 - acc: 0.7105 - val_loss: 0.7679 - val_acc: 0.6968\n",
      "Epoch 49/100\n",
      "36000/36000 [==============================] - 8s 216us/step - loss: 0.7473 - acc: 0.7083 - val_loss: 0.8962 - val_acc: 0.6398\n",
      "Epoch 50/100\n",
      "36000/36000 [==============================] - 8s 215us/step - loss: 0.7425 - acc: 0.7094 - val_loss: 0.7778 - val_acc: 0.6895\n",
      "Epoch 51/100\n",
      "36000/36000 [==============================] - 8s 215us/step - loss: 0.7427 - acc: 0.7082 - val_loss: 0.7969 - val_acc: 0.6787\n",
      "Epoch 52/100\n",
      "36000/36000 [==============================] - 8s 219us/step - loss: 0.7351 - acc: 0.7121 - val_loss: 0.7866 - val_acc: 0.6832\n",
      "Epoch 53/100\n",
      "36000/36000 [==============================] - 8s 214us/step - loss: 0.7321 - acc: 0.7131 - val_loss: 0.7700 - val_acc: 0.6935\n",
      "Epoch 54/100\n",
      "36000/36000 [==============================] - 8s 213us/step - loss: 0.7330 - acc: 0.7124 - val_loss: 0.7614 - val_acc: 0.6993\n",
      "Epoch 55/100\n",
      "36000/36000 [==============================] - 8s 216us/step - loss: 0.7296 - acc: 0.7136 - val_loss: 0.7650 - val_acc: 0.6937\n",
      "Epoch 56/100\n",
      "36000/36000 [==============================] - 8s 216us/step - loss: 0.7288 - acc: 0.7149 - val_loss: 0.8330 - val_acc: 0.6717\n",
      "Epoch 57/100\n",
      "36000/36000 [==============================] - 8s 219us/step - loss: 0.7280 - acc: 0.7138 - val_loss: 0.7932 - val_acc: 0.6736\n",
      "Epoch 58/100\n",
      "36000/36000 [==============================] - 8s 217us/step - loss: 0.7243 - acc: 0.7163 - val_loss: 0.7449 - val_acc: 0.7026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "36000/36000 [==============================] - 8s 210us/step - loss: 0.7122 - acc: 0.7211 - val_loss: 0.7591 - val_acc: 0.6957\n",
      "Epoch 60/100\n",
      "36000/36000 [==============================] - 8s 210us/step - loss: 0.7225 - acc: 0.7160 - val_loss: 0.7587 - val_acc: 0.6932\n",
      "Epoch 61/100\n",
      "36000/36000 [==============================] - 7s 208us/step - loss: 0.7051 - acc: 0.7261 - val_loss: 0.7441 - val_acc: 0.7003\n",
      "Epoch 62/100\n",
      "36000/36000 [==============================] - 8s 212us/step - loss: 0.7111 - acc: 0.7220 - val_loss: 0.7540 - val_acc: 0.6945\n",
      "Epoch 63/100\n",
      "36000/36000 [==============================] - 8s 209us/step - loss: 0.6967 - acc: 0.7289 - val_loss: 0.7354 - val_acc: 0.7055\n",
      "Epoch 64/100\n",
      "36000/36000 [==============================] - 8s 210us/step - loss: 0.7019 - acc: 0.7253 - val_loss: 0.7501 - val_acc: 0.6985\n",
      "Epoch 65/100\n",
      "36000/36000 [==============================] - 8s 211us/step - loss: 0.7040 - acc: 0.7250 - val_loss: 0.7871 - val_acc: 0.6835\n",
      "Epoch 66/100\n",
      "36000/36000 [==============================] - 8s 209us/step - loss: 0.6959 - acc: 0.7283 - val_loss: 0.7328 - val_acc: 0.7065\n",
      "Epoch 67/100\n",
      "36000/36000 [==============================] - 8s 210us/step - loss: 0.6974 - acc: 0.7288 - val_loss: 0.7444 - val_acc: 0.6998\n",
      "Epoch 68/100\n",
      "36000/36000 [==============================] - 8s 213us/step - loss: 0.6892 - acc: 0.7313 - val_loss: 0.7225 - val_acc: 0.7114\n",
      "Epoch 69/100\n",
      "36000/36000 [==============================] - 8s 215us/step - loss: 0.6879 - acc: 0.7317 - val_loss: 0.7280 - val_acc: 0.7087\n",
      "Epoch 70/100\n",
      "36000/36000 [==============================] - 8s 212us/step - loss: 0.6853 - acc: 0.7331 - val_loss: 0.7548 - val_acc: 0.6917\n",
      "Epoch 71/100\n",
      "36000/36000 [==============================] - 8s 216us/step - loss: 0.6925 - acc: 0.7305 - val_loss: 0.7748 - val_acc: 0.6849\n",
      "Epoch 72/100\n",
      "36000/36000 [==============================] - 8s 216us/step - loss: 0.6783 - acc: 0.7359 - val_loss: 0.7413 - val_acc: 0.7031\n",
      "Epoch 73/100\n",
      "36000/36000 [==============================] - 8s 212us/step - loss: 0.6788 - acc: 0.7355 - val_loss: 0.7220 - val_acc: 0.7095\n",
      "Epoch 74/100\n",
      "36000/36000 [==============================] - 8s 213us/step - loss: 0.6684 - acc: 0.7408 - val_loss: 0.7225 - val_acc: 0.7100\n",
      "Epoch 75/100\n",
      "36000/36000 [==============================] - 8s 212us/step - loss: 0.6672 - acc: 0.7412 - val_loss: 0.7305 - val_acc: 0.7071\n",
      "Epoch 76/100\n",
      "36000/36000 [==============================] - 8s 220us/step - loss: 0.6790 - acc: 0.7353 - val_loss: 0.7609 - val_acc: 0.6972\n",
      "Epoch 77/100\n",
      "36000/36000 [==============================] - 8s 215us/step - loss: 0.6692 - acc: 0.7390 - val_loss: 0.7215 - val_acc: 0.7112\n",
      "Epoch 78/100\n",
      "36000/36000 [==============================] - 8s 214us/step - loss: 0.6655 - acc: 0.7410 - val_loss: 0.7347 - val_acc: 0.7017\n",
      "Epoch 79/100\n",
      "36000/36000 [==============================] - 8s 214us/step - loss: 0.6631 - acc: 0.7419 - val_loss: 0.7110 - val_acc: 0.7105\n",
      "Epoch 80/100\n",
      "36000/36000 [==============================] - 8s 214us/step - loss: 0.6542 - acc: 0.7454 - val_loss: 0.7234 - val_acc: 0.7080\n",
      "Epoch 81/100\n",
      "36000/36000 [==============================] - 8s 212us/step - loss: 0.6533 - acc: 0.7457 - val_loss: 0.7032 - val_acc: 0.7173\n",
      "Epoch 82/100\n",
      "36000/36000 [==============================] - 8s 233us/step - loss: 0.6404 - acc: 0.7523 - val_loss: 0.7296 - val_acc: 0.7078\n",
      "Epoch 83/100\n",
      "36000/36000 [==============================] - 8s 216us/step - loss: 0.6620 - acc: 0.7420 - val_loss: 0.7073 - val_acc: 0.7154\n",
      "Epoch 84/100\n",
      "36000/36000 [==============================] - 8s 219us/step - loss: 0.6431 - acc: 0.7505 - val_loss: 0.8436 - val_acc: 0.6704\n",
      "Epoch 85/100\n",
      "36000/36000 [==============================] - 8s 219us/step - loss: 0.6541 - acc: 0.7455 - val_loss: 0.7769 - val_acc: 0.6919\n",
      "Epoch 86/100\n",
      "36000/36000 [==============================] - 8s 214us/step - loss: 0.6385 - acc: 0.7518 - val_loss: 0.7903 - val_acc: 0.6815\n",
      "Epoch 87/100\n",
      "36000/36000 [==============================] - 8s 233us/step - loss: 0.6373 - acc: 0.7517 - val_loss: 0.7082 - val_acc: 0.7148\n",
      "Epoch 88/100\n",
      "36000/36000 [==============================] - 9s 247us/step - loss: 0.6317 - acc: 0.7543 - val_loss: 0.7315 - val_acc: 0.7038\n",
      "Epoch 89/100\n",
      "36000/36000 [==============================] - 8s 214us/step - loss: 0.6186 - acc: 0.7603 - val_loss: 0.7111 - val_acc: 0.7132\n",
      "Epoch 90/100\n",
      "36000/36000 [==============================] - 8s 216us/step - loss: 0.6276 - acc: 0.7556 - val_loss: 0.7009 - val_acc: 0.7179\n",
      "Epoch 91/100\n",
      "36000/36000 [==============================] - 8s 213us/step - loss: 0.6153 - acc: 0.7619 - val_loss: 0.7435 - val_acc: 0.7048\n",
      "Epoch 92/100\n",
      "36000/36000 [==============================] - 8s 214us/step - loss: 0.6363 - acc: 0.7539 - val_loss: 0.7232 - val_acc: 0.7052\n",
      "Epoch 93/100\n",
      "36000/36000 [==============================] - 8s 213us/step - loss: 0.6141 - acc: 0.7608 - val_loss: 0.6877 - val_acc: 0.7225\n",
      "Epoch 94/100\n",
      "36000/36000 [==============================] - 8s 213us/step - loss: 0.6208 - acc: 0.7578 - val_loss: 0.7098 - val_acc: 0.7103\n",
      "Epoch 95/100\n",
      "36000/36000 [==============================] - 8s 213us/step - loss: 0.6129 - acc: 0.7615 - val_loss: 0.7656 - val_acc: 0.6941\n",
      "Epoch 96/100\n",
      "36000/36000 [==============================] - 9s 244us/step - loss: 0.6064 - acc: 0.7646 - val_loss: 0.6911 - val_acc: 0.7230\n",
      "Epoch 97/100\n",
      "36000/36000 [==============================] - 9s 246us/step - loss: 0.6267 - acc: 0.7565 - val_loss: 0.6918 - val_acc: 0.7212\n",
      "Epoch 98/100\n",
      "36000/36000 [==============================] - 11s 299us/step - loss: 0.6011 - acc: 0.7677 - val_loss: 0.6984 - val_acc: 0.7189\n",
      "Epoch 99/100\n",
      "36000/36000 [==============================] - 10s 282us/step - loss: 0.6079 - acc: 0.7629 - val_loss: 0.7065 - val_acc: 0.7167\n",
      "Epoch 100/100\n",
      "36000/36000 [==============================] - 11s 298us/step - loss: 0.6074 - acc: 0.7645 - val_loss: 0.6915 - val_acc: 0.7222\n",
      "Q 2x644   T 1288   \u001b[92m☑\u001b[0m 1288  \n",
      "Q 623x443 T 275989 \u001b[91m☒\u001b[0m 274469\n",
      "Q 142x813 T 115446 \u001b[91m☒\u001b[0m 115326\n",
      "Q 877x97  T 85069  \u001b[91m☒\u001b[0m 86729 \n",
      "Q 469x984 T 461496 \u001b[91m☒\u001b[0m 467016\n",
      "Q 211x562 T 118582 \u001b[91m☒\u001b[0m 117742\n",
      "Q 332x70  T 23240  \u001b[91m☒\u001b[0m 23640 \n",
      "Q 48x25   T 1200   \u001b[92m☑\u001b[0m 1200  \n",
      "Q 254x45  T 11430  \u001b[91m☒\u001b[0m 11330 \n",
      "Q 119x78  T 9282   \u001b[91m☒\u001b[0m 9362  \n"
     ]
    }
   ],
   "source": [
    "for iteration in range(1):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=100,\n",
    "              validation_data=(x_val, y_val))\n",
    "    for i in range(10):\n",
    "        ind = np.random.randint(0, len(x_val))\n",
    "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
    "        preds = model.predict_classes(rowx, verbose=0)\n",
    "        q = ctable.decode(rowx[0])\n",
    "        correct = ctable.decode(rowy[0])\n",
    "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
    "        print('Q', q[::-1] if REVERSE else q, end=' ')\n",
    "        print('T', correct, end=' ')\n",
    "        if correct == guess:\n",
    "            print(colors.ok + '☑' + colors.close, end=' ')\n",
    "        else:\n",
    "            print(colors.fail + '☒' + colors.close, end=' ')\n",
    "        print(guess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6>Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSG : Prediction\n"
     ]
    }
   ],
   "source": [
    "print(\"MSG : Prediction\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
